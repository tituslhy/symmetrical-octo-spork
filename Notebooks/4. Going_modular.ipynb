{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to turn useful notebook code cells into reusable python files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tituslim/Documents/Personal Learning Folder/Data Science/15. PyTorch Developer Class/symmetrical-octo-spork/Notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datasets and dataloaders using `%%writefile` magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists\n"
     ]
    }
   ],
   "source": [
    "# Create directory for going_modular\n",
    "import os\n",
    "if not os.path.exists(\"../going_modular\"):\n",
    "    os.makedirs(\"../going_modular\")\n",
    "else:\n",
    "    print(\"Directory exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../going_modular/data_setup.py\n",
    "\"\"\"\n",
    "Contains functionality for creating PyTorch DataLoaders for\n",
    "image classification tasks.\n",
    "\"\"\"\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int,\n",
    "    num_workers: int = NUM_WORKERS\n",
    ") -> Tuple[torch.utils.data.DataLoader, \n",
    "           torch.utils.data.DataLoader,\n",
    "           List]:\n",
    "    \"\"\"Creates torch datasets and subsequently dataloaders for training\n",
    "    and testing sets. \n",
    "\n",
    "    Args:\n",
    "        train_dir (str): Filepath to train data\n",
    "        test_dir (str): Filepath to test data\n",
    "        transform (transforms.Compose): torch transforms.Compose object\n",
    "        batch_size: Number of samples per batch in each of the datalaoders\n",
    "        num_workers (int, optional): Defaults to NUM_WORKERS.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_dataloader, test_dataloader, class_names) where\n",
    "        classnames is a list of the target classes.\n",
    "    \"\"\"\n",
    "    train_data = datasets.ImageFolder(root = train_dir,\n",
    "                                      transform = transform)\n",
    "    class_names = train_data.classes\n",
    "    test_data = datasets.ImageFolder(root = test_dir,\n",
    "                                      transform = transform)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_data,\n",
    "                                  batch_size = batch_size,\n",
    "                                  shuffle = True,\n",
    "                                  num_workers = num_workers,\n",
    "                                  pin_memory = True\n",
    "                                  )\n",
    "    \n",
    "    test_dataloader = DataLoader(test_data,\n",
    "                                  batch_size = batch_size,\n",
    "                                  shuffle = False,\n",
    "                                  num_workers = num_workers,\n",
    "                                  pin_memory = True\n",
    "                                  )\n",
    "    \n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizza', 'steak', 'sushi']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from going_modular import data_setup\n",
    "from torchvision import transforms\n",
    "\n",
    "train_dir = \"./data/pizza_steak_sushi/train/\"\n",
    "test_dir = \"./data/pizza_steak_sushi/test/\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size = (224,224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir = train_dir,\n",
    "    test_dir = test_dir,\n",
    "    transform = transform,\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../going_modular/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../going_modular/model_builder.py\n",
    "\"\"\"Contains pytorch code to develop TinyVGG architecture\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 num_channels: int = 3, \n",
    "                 hidden_units: int = 10,\n",
    "                 num_classes: int = 3):\n",
    "        \"\"\"Class constructor\n",
    "\n",
    "        Args:\n",
    "            num_channels (int): Number of color channels\n",
    "            hidden_units (int): Number of hidden units in model\n",
    "            num_classes (int): Number of labels. Set to 3 for pizza, steak, sushi\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_channels, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=1), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "            nn.Linear(in_features=hidden_units*16*16,\n",
    "                      out_features=num_classes)\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Overrides forward method from parent. Runs a forward pass\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Image data in tensor format\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Logits\n",
    "        \"\"\"\n",
    "        # x = self.conv_block_1(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.conv_block_2(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.classifier(x)\n",
    "        # # print(x.shape)\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- leverage the benefits of operator fusion\n",
    "\n",
    "class TinyVGG2(nn.Module):\n",
    "    \"\"\"Extension of the TinyVGG model with double the\n",
    "    number of hidden units.\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "  def __init__(self, \n",
    "               num_color_channels: int = 3, \n",
    "               hidden_units: int = 20, \n",
    "               num_classes: int = 3):\n",
    "    super().__init__()\n",
    "    self.conv_block_1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels = num_color_channels,\n",
    "                  out_channels = hidden_units,\n",
    "                  kernel_size = 3,\n",
    "                  stride = 1,\n",
    "                  padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = hidden_units,\n",
    "                  out_channels = hidden_units,\n",
    "                  kernel_size = 3,\n",
    "                  stride = 1,\n",
    "                  padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size = 2,\n",
    "                     stride = 2)\n",
    "    )\n",
    "    self.conv_block_2 = nn.Sequential(\n",
    "        nn.Conv2d(hidden_units, hidden_units, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(hidden_units, hidden_units, kernel_size = 3, padding =1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features = hidden_units * 56 * 56,\n",
    "                  out_features = num_classes)\n",
    "    )\n",
    "  def forward(self, x: torch.Tensor):\n",
    "      return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyVGG2                                 [32, 3]                   --\n",
       "├─Sequential: 1-1                        [32, 20, 112, 112]        --\n",
       "│    └─Conv2d: 2-1                       [32, 20, 224, 224]        560\n",
       "│    └─ReLU: 2-2                         [32, 20, 224, 224]        --\n",
       "│    └─Conv2d: 2-3                       [32, 20, 224, 224]        3,620\n",
       "│    └─ReLU: 2-4                         [32, 20, 224, 224]        --\n",
       "│    └─MaxPool2d: 2-5                    [32, 20, 112, 112]        --\n",
       "├─Sequential: 1-2                        [32, 20, 56, 56]          --\n",
       "│    └─Conv2d: 2-6                       [32, 20, 112, 112]        3,620\n",
       "│    └─ReLU: 2-7                         [32, 20, 112, 112]        --\n",
       "│    └─Conv2d: 2-8                       [32, 20, 112, 112]        3,620\n",
       "│    └─ReLU: 2-9                         [32, 20, 112, 112]        --\n",
       "│    └─MaxPool2d: 2-10                   [32, 20, 56, 56]          --\n",
       "├─Sequential: 1-3                        [32, 3]                   --\n",
       "│    └─Flatten: 2-11                     [32, 62720]               --\n",
       "│    └─Linear: 2-12                      [32, 3]                   188,163\n",
       "==========================================================================================\n",
       "Total params: 199,583\n",
       "Trainable params: 199,583\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 9.62\n",
       "==========================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 642.25\n",
       "Params size (MB): 0.80\n",
       "Estimated Total Size (MB): 662.32\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from going_modular import model_builder\n",
    "sys.path.append(os.path.join(os.getcwd(),\n",
    "                             \"../src\"))\n",
    "from utils import get_device\n",
    "device = get_device()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.mps.manual_seed(42)\n",
    "model = model_builder.TinyVGG2(num_color_channels=3,\n",
    "                               hidden_units = 20,\n",
    "                               num_classes = len(class_names)).to(device)\n",
    "summary(model, input_size = [32, 3, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "img.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([32, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img)\n",
    "type(out), out.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrting our training and testing step functions into a python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../going_modular/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../going_modular/engine.py\n",
    "\"\"\"Contains functions for training and testing a PyTorch model\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: str) -> Tuple[float, float]:\n",
    "    \"\"\"Helper function to train pytorch model on device\n",
    "    and acquire training metrics per epoch\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): instantiated torch model\n",
    "        dataloader (torch.utils.data.DataLoader)\n",
    "        loss_fn (torch.nn.Module)\n",
    "        optimizer (torch.optim.Optimizer) \n",
    "        device (str): Torch device\n",
    "\n",
    "    Returns:\n",
    "        Average training loss and training accuracy per epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    train_loss, train_acc = 0,0\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        # Forward pass\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X) #logits\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute metric across all batches\n",
    "        y_pred_class = torch.argmax(\n",
    "            torch.softmax(y_pred, dim = 1),\n",
    "            dim = 1\n",
    "        )\n",
    "\n",
    "        train_acc += (y_pred_class==y).sum().item()/len(y_pred)\n",
    "    \n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc/len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: str) -> Tuple[float, float]:\n",
    "    \"\"\"Runs inference of trained model on test dataset per epoch\n",
    "    and monitors model test metrics.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): instantiated torch model\n",
    "        dataloader (torch.utils.data.DataLoader)\n",
    "        loss_fn (torch.nn.Module)\n",
    "        device (str, optional): _description_. Defaults to device.\n",
    "\n",
    "    Returns:\n",
    "        Average test loss and test accuracy per epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    test_loss, test_acc = 0,0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            \n",
    "            # Forward pass\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_pred = model(X) #logits\n",
    "\n",
    "            # Compute metrics \n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_pred_class = torch.argmax(\n",
    "                torch.softmax(test_pred, dim = 1),\n",
    "                dim = 1\n",
    "            )\n",
    "            test_acc += (test_pred_class == y).sum().item()/len(test_pred_class)\n",
    "    \n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "    test_acc = test_acc/len(dataloader)\n",
    "    \n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss()): \n",
    "    \"\"\"Wrapper function to train model over specified number of epochs,\n",
    "    model, dataloaders, optimizer and loss function.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): instantiated torch model\n",
    "        train_dataloader (torch.utils.data.DataLoader)\n",
    "        test_dataloader (torch.utils.data.DataLoader)\n",
    "        optimizer (torch.optim.Optimizer)\n",
    "        epochs (int): Number of epochs for training\n",
    "        loss_fn (torch.nn.Module, optional) Defaults to nn.CrossEntropyLoss().\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create storage results dictionary\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    # Loop through training and testing steps for number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model = model,\n",
    "                                           dataloader = train_dataloader,\n",
    "                                           loss_fn = loss_fn,\n",
    "                                           optimizer = optimizer)\n",
    "        test_loss, test_acc = test_step(model = model,\n",
    "                                        dataloader = test_dataloader,\n",
    "                                        loss_fn = loss_fn)\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test functions imported!\n"
     ]
    }
   ],
   "source": [
    "from going_modular import engine\n",
    "print(\"Train and test functions imported!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning our utility functions for saving a model into a python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../going_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../going_modular/utils.py\n",
    "\"\"\"Utility functions for torch driven computer vision projects\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "def save_model(root_dir: str,\n",
    "               model_name: str,\n",
    "               model: torch.nn.Module):\n",
    "    \"\"\"Saves a torch model to the given root directory\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Name of directory to store model\n",
    "        model_name (str): Name of the model\n",
    "        model (torch.nn.Module): Torch model object\n",
    "    \"\"\"\n",
    "    MODEL_PATH = Path(root_dir)\n",
    "    MODEL_PATH.mkdir(parents=True,\n",
    "                     exist_ok = True)\n",
    "    MODEL_NAME = model_name\n",
    "    MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "    torch.save(obj = model.state_dict(),\n",
    "            f = MODEL_SAVE_PATH)\n",
    "    print(f\"Saved model to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utils imported!\n"
     ]
    }
   ],
   "source": [
    "from going_modular import utils\n",
    "print(\"Utils imported!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
