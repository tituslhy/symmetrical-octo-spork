{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.utils import get_device, plot_loss_curves\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create model and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "model_weights = models.ResNet50_Weights.DEFAULT\n",
    "transforms = model_weights.transforms()\n",
    "\n",
    "model = models.resnet50(weights = model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total number of parameters: 25557032\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(param.numel() for param in model.parameters())\n",
    "print(f\"[INFO] Total number of parameters: {total_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch speedups will be most noticeable when as much of the GPU is being used. This means that a larger model may take longer to train on the whole but will be much faster to train than if it were to be trained without using torch 2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(in_features = 2048,\n",
    "                           out_features = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can increase GPU utilization by:\n",
    "* Using larger models\n",
    "* Increasing the batch size\n",
    "* Increase the data size (use 224 x 224 dimension images)\n",
    "* Increase embedding size for data\n",
    "* Decreasing data transfer: transferring data across devices will slow down a GPU."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check device memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n",
      "mps memory info: 262.242 MB\n"
     ]
    }
   ],
   "source": [
    "if get_device() == 'cuda':\n",
    "    total_free_memory, total_memory = torch.cuda.mem_get_info()\n",
    "    print(f'Device is cuda')\n",
    "    print(f\"Total free GPU memory: {round(total_free_memory * 1e-9, 3)} GB\")\n",
    "    print(f\"Total GPU memory: {round(total_memory * 1e-9, 3)} GB\")\n",
    "elif get_device() == 'mps':\n",
    "    print(f'Device is mps')\n",
    "    from torch import mps\n",
    "    total_memory = mps.driver_allocated_memory()\n",
    "    print(f\"mps memory info: {round(mps.driver_allocated_memory()*1e-6, 3)} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if round(total_memory * 1e-9, 3) >= 16:\n",
    "    BATCH_SIZE = 128\n",
    "    IMAGE_SIZE = 224\n",
    "else:\n",
    "    BATCH_SIZE = 32\n",
    "    IMAGE_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=128\n",
       "    resize_size=128\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update transforms\n",
    "transforms.crop_size = IMAGE_SIZE\n",
    "transforms.resize_size = IMAGE_SIZE\n",
    "transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Not using cuda device. Skip setting Tensorfloat32\n"
     ]
    }
   ],
   "source": [
    "if get_device() == 'cuda':\n",
    "    major, minor = torch.cuda.get_device_capability(get_device())\n",
    "    GPU_SCORE = major + float(\"0.\" + str(minor))\n",
    "    if GPU_SCORE >= 8.0:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        print(f\"[INFO] Using GPU with {GPU_SCORE} compute capability, enabling TensorFloat32\")\n",
    "    else:\n",
    "        print(f\"[INFO] Using GPU with {GPU_SCORE} compute capability, not enabling TensorFloat32\")\n",
    "else:\n",
    "    print(f\"[INFO] Not using cuda device. Skip setting Tensorfloat32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[INFO] Train dataset length: 50000\n",
      "[INFO] Test dataset length: 10000\n"
     ]
    }
   ],
   "source": [
    "# Create train and test datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='.', \n",
    "                                             train=True, \n",
    "                                             download=True, \n",
    "                                             transform=transforms)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='.', \n",
    "                                            train=False, # want the test split\n",
    "                                            download=True, \n",
    "                                            transform=transforms)\n",
    "\n",
    "# Get the lengths of the datasets\n",
    "train_len = len(train_dataset)\n",
    "test_len = len(test_dataset)\n",
    "\n",
    "print(f\"[INFO] Train dataset length: {train_len}\")\n",
    "print(f\"[INFO] Test dataset length: {test_len}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "train_dataloader = DataLoader(dataset = train_dataset,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle = True,\n",
    "                              num_workers = NUM_WORKERS)\n",
    "test_dataloader = DataLoader(dataset = test_dataset,\n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             shuffle = False,\n",
    "                             num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(epoch: int,\n",
    "               model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device,\n",
    "               disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "    \"\"\"Trains a PyTorch model for a single epoch\n",
    "\n",
    "    Args:\n",
    "        epoch (int): epoch number\n",
    "        loss_fn (torch.nn.Module): PyTorch loss function to minimize\n",
    "        optimizer (torch.optim.Optimizer): PyTorch optimizer object\n",
    "        device (torch.device): PyTorch device\n",
    "        model (_type_, optional): _description_. Defaults to torch.nn.Module.\n",
    "        dataloader (_type_, optional): _description_. Defaults to torch.utils.data.DataLoader.\n",
    "        disable_progress_bar (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: _description_\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0,0\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(dataloader),\n",
    "        desc = f\"Training Epoch {epoch}\",\n",
    "        total = len(dataloader),\n",
    "        disable = disable_progress_bar\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "592c8f2936c3bb8c4fbb52cdfc4075c16174c85ffa67c8cedffd3a3aa9257d1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
